{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "name": "dpr.ipynb",
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/stnava/061b2cb8f79c582822e539f238809bd8/xray_sr_randpatch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsqY-Ru_R7Mu",
        "outputId": "5251d88b-84a2-4dac-d70b-33aada3ba0cf"
      },
      "source": [
        "#!/usr/bin/python3\n",
        "import os.path\n",
        "from os import path\n",
        "# !pip uninstall antspyx\n",
        "!pip install antspyx\n",
        "!pip install git+https://github.com/ANTsX/ANTsPyNet\n",
        "import ants"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: antspyx in /usr/local/lib/python3.7/dist-packages (0.3.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from antspyx) (7.1.2)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from antspyx) (0.12.2)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.7/dist-packages (from antspyx) (3.0.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from antspyx) (6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from antspyx) (1.7.3)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from antspyx) (0.18.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from antspyx) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from antspyx) (1.0.2)\n",
            "Requirement already satisfied: chart-studio in /usr/local/lib/python3.7/dist-packages (from antspyx) (1.1.0)\n",
            "Requirement already satisfied: webcolors in /usr/local/lib/python3.7/dist-packages (from antspyx) (1.12)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from antspyx) (1.3.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from antspyx) (3.2.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from chart-studio->antspyx) (5.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from chart-studio->antspyx) (2.23.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from chart-studio->antspyx) (1.3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from chart-studio->antspyx) (1.15.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->antspyx) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->antspyx) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->antspyx) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->antspyx) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->antspyx) (4.1.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->antspyx) (2022.2.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->chart-studio->antspyx) (8.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->chart-studio->antspyx) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->chart-studio->antspyx) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->chart-studio->antspyx) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->chart-studio->antspyx) (1.24.3)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->antspyx) (2.9.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->antspyx) (2.6.3)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->antspyx) (1.3.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->antspyx) (2021.11.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->antspyx) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->antspyx) (1.1.0)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.7/dist-packages (from statsmodels->antspyx) (0.5.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/ANTsX/ANTsPyNet\n",
            "  Cloning https://github.com/ANTsX/ANTsPyNet to /tmp/pip-req-build-09f6ffgk\n",
            "  Running command git clone -q https://github.com/ANTsX/ANTsPyNet /tmp/pip-req-build-09f6ffgk\n",
            "Requirement already satisfied: antspyx in /usr/local/lib/python3.7/dist-packages (from antspynet==0.1.8) (0.3.3)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from antspynet==0.1.8) (2.8.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from antspynet==0.1.8) (1.0.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from antspynet==0.1.8) (2.8.2+zzzcolab20220719082949)\n",
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.7/dist-packages (from antspynet==0.1.8) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from antspynet==0.1.8) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from antspynet==0.1.8) (2.23.0)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from antspynet==0.1.8) (0.12.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from antspynet==0.1.8) (3.2.2)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.7/dist-packages (from antspyx->antspynet==0.1.8) (3.0.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from antspyx->antspynet==0.1.8) (0.18.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from antspyx->antspynet==0.1.8) (7.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from antspyx->antspynet==0.1.8) (1.7.3)\n",
            "Requirement already satisfied: chart-studio in /usr/local/lib/python3.7/dist-packages (from antspyx->antspynet==0.1.8) (1.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from antspyx->antspynet==0.1.8) (1.3.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from antspyx->antspynet==0.1.8) (6.0)\n",
            "Requirement already satisfied: webcolors in /usr/local/lib/python3.7/dist-packages (from antspyx->antspynet==0.1.8) (1.12)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from chart-studio->antspyx->antspynet==0.1.8) (5.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from chart-studio->antspyx->antspynet==0.1.8) (1.15.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from chart-studio->antspyx->antspynet==0.1.8) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->antspynet==0.1.8) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->antspynet==0.1.8) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->antspynet==0.1.8) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->antspynet==0.1.8) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->antspynet==0.1.8) (4.1.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->antspyx->antspynet==0.1.8) (2022.2.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->chart-studio->antspyx->antspynet==0.1.8) (8.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->antspynet==0.1.8) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->antspynet==0.1.8) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->antspynet==0.1.8) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->antspynet==0.1.8) (3.0.4)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->antspyx->antspynet==0.1.8) (2.6.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->antspyx->antspynet==0.1.8) (2021.11.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->antspyx->antspynet==0.1.8) (2.9.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->antspyx->antspynet==0.1.8) (1.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->antspynet==0.1.8) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->antspynet==0.1.8) (3.1.0)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.7/dist-packages (from statsmodels->antspynet==0.1.8) (0.5.2)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->antspynet==0.1.8) (2.8.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->antspynet==0.1.8) (2.0.7)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->antspynet==0.1.8) (1.48.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->antspynet==0.1.8) (0.26.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->antspynet==0.1.8) (1.14.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->antspynet==0.1.8) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow->antspynet==0.1.8) (57.4.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->antspynet==0.1.8) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->antspynet==0.1.8) (1.1.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->antspynet==0.1.8) (3.17.3)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->antspynet==0.1.8) (14.0.6)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->antspynet==0.1.8) (3.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->antspynet==0.1.8) (1.6.3)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->antspynet==0.1.8) (0.5.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->antspynet==0.1.8) (2.8.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->antspynet==0.1.8) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->antspynet==0.1.8) (1.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->antspynet==0.1.8) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->antspynet==0.1.8) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->antspynet==0.1.8) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->antspynet==0.1.8) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->antspynet==0.1.8) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->antspynet==0.1.8) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->antspynet==0.1.8) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->antspynet==0.1.8) (0.6.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->antspynet==0.1.8) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->antspynet==0.1.8) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->antspynet==0.1.8) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->antspynet==0.1.8) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->antspynet==0.1.8) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->antspynet==0.1.8) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->antspynet==0.1.8) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->antspynet==0.1.8) (3.2.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability->antspynet==0.1.8) (0.1.7)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability->antspynet==0.1.8) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability->antspynet==0.1.8) (1.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ants"
      ],
      "metadata": {
        "id": "l6WW-b1iqkV7"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhslk4gmgi3o",
        "outputId": "283cd92c-93eb-4492-ef3f-00c6004bd6f5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AJi3CH1R7Mw"
      },
      "source": [
        "**overview**<br>\n",
        "<br>\n",
        "we are reviewing a simple script for training a super-resolution network<br>\n",
        "that uses a straightforward approach and does not require a discriminator<br>\n",
        "network which is, generally speaking, much harder to optimize/control.<br>\n",
        "instead, we rely on total variation and perceptual losses in addition to<br>\n",
        "the standard reconstruction loss ( mean squared error ).  while this is<br>\n",
        "done in TF, it could be implemented transparently in pytorch or whatever.<br>\n",
        "the implementation will also work in 3D if weight transfer is done as<br>\n",
        "explained [here](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7279929/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AS1qm-AR7Mw"
      },
      "source": [
        "**goals**<br>\n",
        "provide a conceptual and practical foundation for how to train a super-Resolution<br>\n",
        "network.  ideally, we can collectively identify a better network, parameter set,<br>\n",
        "evaluation criterion, perceptual loss or other feature that would improve<br>\n",
        "on what we have now.  the hyperplane and DGX resources support such efforts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xn79__7aR7Mx"
      },
      "source": [
        "**glossary**<br>\n",
        "<br>\n",
        "[*super-resolution*](https://scholar.google.com/scholar?q=super-resolution+image&hl=en&as_sdt=0%2C30&as_ylo=1965&as_yhi=1977): a typically nonlinear approach to upsampling data in order<br>\n",
        "to increase the effective or perceived image resolution.<br>\n",
        "<br>\n",
        "*deep backprojection network (DBPN)*: Haris et al Deep Back-Projection Networks For Super-Resolution<br>\n",
        "a residual network that does both up and downsampling and uses perceptual losses.<br>\n",
        "the number of backprojection layers relates to how many residual layers exist.<br>\n",
        "[references here](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C30&q=haris+deep+back+projection+network&btnG=)<br>\n",
        "<br>\n",
        "*perceptual loss*: - a loss function that maps raw image features to a<br>\n",
        "higher-dimensional feature space defined by a pre-trained network<br>\n",
        "[references](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C30&q=perceptual+losses+super+resolution&btnG=&oq=perceptual+losses+super)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaNMAfvYR7Mx"
      },
      "source": [
        "**input parameters**<br>\n",
        "<br>\n",
        "user defined parameters below - they include options for perceptual features<br>\n",
        "the number of back-projection layers, patch scaling options and weighting<br>\n",
        "terms for the loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k23Q4xIUR7Mx",
        "outputId": "7f4eebb9-01e4-4715-8281-c511d7a8c310"
      },
      "source": [
        "import sys\n",
        "arglist = (sys.argv)\n",
        "print( arglist )\n",
        "arglist=[\"name\",5,\"True\",0.5,256,\"True\",\"True\"]\n",
        "nbp=int( arglist[1] )\n",
        "do22=(arglist[2] == \"True\" ) | (arglist[2] == 1 )\n",
        "featureWeight = 200.0\n",
        "ctmod = 10\n",
        "mybs  = 1028\n",
        "patch_scale = True\n",
        "if do22 == 1:\n",
        "    featureWeight = 0.25"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py', '-f', '/root/.local/share/jupyter/runtime/kernel-d3c370d3-5046-42b7-a6b9-9c095ccda3d8.json']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpFfGws0R7My"
      },
      "source": [
        "**Note**: loss function weights are important for performance and are typically<br>\n",
        "set empirically or by parameter search where quality is assessed against an independent metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93vWk_W9R7My",
        "outputId": "4cfad576-1078-4976-c59a-83e2721c778b"
      },
      "source": [
        "if len( arglist ) > 3:\n",
        "    featureWeight = float( arglist[3] )\n",
        "    print( \"featureWeight\" + str( featureWeight) )\n",
        "if len( arglist ) > 4:\n",
        "    ctmod = int( arglist[4] )\n",
        "if len( arglist ) > 5:\n",
        "    patch_scale = arglist[5] == \"True\""
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "featureWeight0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3Pu5NEYR7My"
      },
      "source": [
        "set up naming such that we know something about the stored network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZOcwejiR7Mz",
        "outputId": "9c967ef9-bd28-44d6-fca3-362da6fbc923"
      },
      "source": [
        "ofn = \"dbpnn-nbp\" + str(nbp) + '-ctmod' + str(ctmod) + \"-patchscale\" + str(patch_scale) +  \"-vggfeat54.h5\"\n",
        "if do22:\n",
        "    ofn = \"dbpnn-nbp\" + str(nbp) + '-ctmod' + str(ctmod) +\"-patchscale\" + str(patch_scale) +  \"-vggfeat22_p3eq.h5\"\n",
        "print( \"network config: \" + ofn, flush=True )\n",
        "print( \"weight: \" + str( featureWeight ), flush=True  )"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "network config: dbpnn-nbp5-ctmod256-patchscaleTrue-vggfeat22_p3eq.h5\n",
            "weight: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsJkYtmZR7Mz"
      },
      "source": [
        "standard imports for I/O, sampling and image manipulation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pZ9NJslR7Mz"
      },
      "source": [
        "import ants\n",
        "import antspynet\n",
        "import random\n",
        "import glob as glob\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import ants\n",
        "import tensorflow.keras as keras\n",
        "featureWeight = tf.constant( featureWeight )"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygnhUy6sR7Mz"
      },
      "source": [
        "**dependencies**<br>\n",
        "1. tensorflow 2.0 or higher<br>\n",
        "2. [ANTsPy](https://github.com/ANTsX/ANTsPy)<br>\n",
        "3. [ANTsPyNet](https://github.com/ANTsX/ANTsPyNet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBE7dsn2R7M0"
      },
      "source": [
        "we use freely available data for reference - one can get started with just<br>\n",
        "one of the tar.gz files - these should be unzipped and will result in a folder<br>\n",
        "called \"images/\" with a bunch of jpgs in it<br>\n",
        "get data from here https://nihcc.app.box.com/v/ChestXray-NIHCC/folder/37178474737"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BO_DRqkLR7M0"
      },
      "source": [
        "import the VGG19 network with pre-trained weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M50mLJJPR7M0"
      },
      "source": [
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "# our VGG19 assumes data is centered about 0 with a range of 255 the\n",
        "# offset intensity controls this where range is offsetIntensity*2\n",
        "offsetIntensity = 127.5"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpslhAbfR7M0"
      },
      "source": [
        "load in relevant objects from keras so we can build our network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZKGv44GR7M0"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import (Input, Add, Subtract,\n",
        "                          PReLU, Concatenate,\n",
        "                          UpSampling2D, UpSampling3D,\n",
        "                          Conv2D, Conv2DTranspose,\n",
        "                          Conv3D, Conv3DTranspose)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gj98IcQAR7M1"
      },
      "source": [
        "define the DBPN network - this uses a model definition that is general to<br>\n",
        "both 2D and 3D. recommended parameters for different upsampling rates can<br>\n",
        "be found in the papers by Haris et al.  We make one significant change to<br>\n",
        "the original architecture by allowing standard interpolation for upsampling<br>\n",
        "instead of convolutional upsampling.  this is controlled by the interpolation<br>\n",
        "option."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1VLDGykR7M1"
      },
      "source": [
        "def dbpn(input_image_size,\n",
        "                                                 number_of_outputs=1,\n",
        "                                                 number_of_base_filters=64,\n",
        "                                                 number_of_feature_filters=256,\n",
        "                                                 number_of_back_projection_stages=7,\n",
        "                                                 convolution_kernel_size=(12, 12),\n",
        "                                                 strides=(8, 8),\n",
        "                                                 last_convolution=(3, 3),\n",
        "                                                 number_of_loss_functions=1,\n",
        "                                                 interpolation = 'nearest'\n",
        "                                                ):\n",
        "    idim = len( input_image_size ) - 1\n",
        "    if idim == 2:\n",
        "        myconv = Conv2D\n",
        "        myconv_transpose = Conv2DTranspose\n",
        "        myupsampling = UpSampling2D\n",
        "        shax = ( 1, 2 )\n",
        "        firstConv = (3,3)\n",
        "        firstStrides=(1,1)\n",
        "        smashConv=(1,1)\n",
        "    if idim == 3:\n",
        "        myconv = Conv3D\n",
        "        myconv_transpose = Conv3DTranspose\n",
        "        myupsampling = UpSampling3D\n",
        "        shax = ( 1, 2, 3 )\n",
        "        firstConv = (3,3,3)\n",
        "        firstStrides=(1,1,1)\n",
        "        smashConv=(1,1,1)\n",
        "    def up_block_2d(L, number_of_filters=64, kernel_size=(12, 12), strides=(8, 8),\n",
        "                    include_dense_convolution_layer=True):\n",
        "        if include_dense_convolution_layer == True:\n",
        "            L = myconv(filters = number_of_filters,\n",
        "                       use_bias=True,\n",
        "                       kernel_size=smashConv,\n",
        "                       strides=firstStrides,\n",
        "                       padding='same')(L)\n",
        "            L = PReLU(alpha_initializer='zero',\n",
        "                      shared_axes=shax)(L)\n",
        "        # Scale up\n",
        "        if idim == 2:\n",
        "            H0 = myupsampling( size = strides, interpolation=interpolation )(L)\n",
        "        if idim == 3:\n",
        "            H0 = myupsampling( size = strides )(L)\n",
        "        H0 = myconv(filters=number_of_filters,\n",
        "                    kernel_size=firstConv,\n",
        "                    strides=firstStrides,\n",
        "                    use_bias=True,\n",
        "                    padding='same')(H0)\n",
        "        H0 = PReLU(alpha_initializer='zero',\n",
        "                   shared_axes=shax)(H0)\n",
        "        # Scale down\n",
        "        L0 = myconv(filters=number_of_filters,\n",
        "                    kernel_size=kernel_size,\n",
        "                    strides=strides,\n",
        "                    kernel_initializer='glorot_uniform',\n",
        "                    padding='same')(H0)\n",
        "        L0 = PReLU(alpha_initializer='zero',\n",
        "                   shared_axes=shax)(L0)\n",
        "        # Residual\n",
        "        E = Subtract()([L0, L])\n",
        "        # Scale residual up\n",
        "        if idim == 2:\n",
        "            H1 = myupsampling( size = strides, interpolation=interpolation  )(E)\n",
        "        if idim == 3:\n",
        "            H1 = myupsampling( size = strides )(E)\n",
        "        H1 = myconv(filters=number_of_filters,\n",
        "                    kernel_size=firstConv,\n",
        "                    strides=firstStrides,\n",
        "                    use_bias=True,\n",
        "                    padding='same')(H1)\n",
        "        H1 = PReLU(alpha_initializer='zero',\n",
        "                   shared_axes=shax)(H1)\n",
        "        # Output feature map\n",
        "        up_block = Add()([H0, H1])\n",
        "        return up_block\n",
        "    def down_block_2d(H, number_of_filters=64, kernel_size=(12, 12), strides=(8, 8),\n",
        "                    include_dense_convolution_layer=True):\n",
        "        if include_dense_convolution_layer == True:\n",
        "            H = myconv(filters = number_of_filters,\n",
        "                       use_bias=True,\n",
        "                       kernel_size=smashConv,\n",
        "                       strides=firstStrides,\n",
        "                       padding='same')(H)\n",
        "            H = PReLU(alpha_initializer='zero',\n",
        "                      shared_axes=shax)(H)\n",
        "        # Scale down\n",
        "        L0 = myconv(filters=number_of_filters,\n",
        "                    kernel_size=kernel_size,\n",
        "                    strides=strides,\n",
        "                    kernel_initializer='glorot_uniform',\n",
        "                    padding='same')(H)\n",
        "        L0 = PReLU(alpha_initializer='zero',\n",
        "                   shared_axes=shax)(L0)\n",
        "        # Scale up\n",
        "        if idim == 2:\n",
        "            H0 = myupsampling( size = strides, interpolation=interpolation )(L0)\n",
        "        if idim == 3:\n",
        "            H0 = myupsampling( size = strides )(L0)\n",
        "        H0 = myconv(filters=number_of_filters,\n",
        "                    kernel_size=firstConv,\n",
        "                    strides=firstStrides,\n",
        "                    use_bias=True,\n",
        "                    padding='same')(H0)\n",
        "        H0 = PReLU(alpha_initializer='zero',\n",
        "                   shared_axes=shax)(H0)\n",
        "        # Residual\n",
        "        E = Subtract()([H0, H])\n",
        "        # Scale residual down\n",
        "        L1 = myconv(filters=number_of_filters,\n",
        "                    kernel_size=kernel_size,\n",
        "                    strides=strides,\n",
        "                    kernel_initializer='glorot_uniform',\n",
        "                    padding='same')(E)\n",
        "        L1 = PReLU(alpha_initializer='zero',\n",
        "                   shared_axes=shax)(L1)\n",
        "        # Output feature map\n",
        "        down_block = Add()([L0, L1])\n",
        "        return down_block\n",
        "    inputs = Input(shape=input_image_size)\n",
        "    # Initial feature extraction\n",
        "    model = myconv(filters=number_of_feature_filters,\n",
        "                   kernel_size=firstConv,\n",
        "                   strides=firstStrides,\n",
        "                   padding='same',\n",
        "                   kernel_initializer='glorot_uniform')(inputs)\n",
        "    model = PReLU(alpha_initializer='zero',\n",
        "                  shared_axes=shax)(model)\n",
        "    # Feature smashing\n",
        "    model = myconv(filters=number_of_base_filters,\n",
        "                   kernel_size=smashConv,\n",
        "                   strides=firstStrides,\n",
        "                   padding='same',\n",
        "                   kernel_initializer='glorot_uniform')(model)\n",
        "    model = PReLU(alpha_initializer='zero',\n",
        "                  shared_axes=shax)(model)\n",
        "    # Back projection\n",
        "    up_projection_blocks = []\n",
        "    down_projection_blocks = []\n",
        "    model = up_block_2d(model, number_of_filters=number_of_base_filters,\n",
        "      kernel_size=convolution_kernel_size, strides=strides)\n",
        "    up_projection_blocks.append(model)\n",
        "    for i in range(number_of_back_projection_stages):\n",
        "        if i == 0:\n",
        "            model = down_block_2d(model, number_of_filters=number_of_base_filters,\n",
        "              kernel_size=convolution_kernel_size, strides=strides)\n",
        "            down_projection_blocks.append(model)\n",
        "            model = up_block_2d(model, number_of_filters=number_of_base_filters,\n",
        "              kernel_size=convolution_kernel_size, strides=strides)\n",
        "            up_projection_blocks.append(model)\n",
        "            model = Concatenate()(up_projection_blocks)\n",
        "        else:\n",
        "            model = down_block_2d(model, number_of_filters=number_of_base_filters,\n",
        "              kernel_size=convolution_kernel_size, strides=strides,\n",
        "              include_dense_convolution_layer=True)\n",
        "            down_projection_blocks.append(model)\n",
        "            model = Concatenate()(down_projection_blocks)\n",
        "            model = up_block_2d(model, number_of_filters=number_of_base_filters,\n",
        "              kernel_size=convolution_kernel_size, strides=strides,\n",
        "              include_dense_convolution_layer=True)\n",
        "            up_projection_blocks.append(model)\n",
        "            model = Concatenate()(up_projection_blocks)\n",
        "    outputs = myconv(filters=number_of_outputs,\n",
        "                     kernel_size=last_convolution,\n",
        "                     strides=firstStrides,\n",
        "                     padding = 'same',\n",
        "                     kernel_initializer = \"glorot_uniform\")(model)\n",
        "    if number_of_loss_functions == 1:\n",
        "        deep_back_projection_network_model = Model(inputs=inputs, outputs=outputs)\n",
        "    else:\n",
        "        outputList=[]\n",
        "        for k in range(number_of_loss_functions):\n",
        "            outputList.append(outputs)\n",
        "        deep_back_projection_network_model = Model(inputs=inputs, outputs=outputList)\n",
        "    return deep_back_projection_network_model"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrIYJtgTR7M1"
      },
      "source": [
        "will build testing data on the fly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIGsyqs3R7M2"
      },
      "source": [
        "do_test = True"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uxzfy9tyR7M2"
      },
      "source": [
        "set up strides and patch sizes - **these could also be explored empirically**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlFOUrrkR7M2"
      },
      "source": [
        "st = 96\n",
        "psz = 32\n",
        "# we are doing 2x SR so low-res size is just 48\n",
        "lsz = int(psz/2)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wqWOe0kR7M2"
      },
      "source": [
        "generate a random corner index for a patch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTGxO1fTR7M2"
      },
      "source": [
        "def get_random_base_ind( full_dims=(1024,1024), off = 10, patchWidth = 96 ):\n",
        "    baseInd = [None,None]\n",
        "    for k in range(2):\n",
        "        baseInd[k]=random.sample( range( off, full_dims[k]-1-patchWidth ), 1 )[0]\n",
        "    return baseInd"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lFFOvb0R7M3"
      },
      "source": [
        "extract a random patch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hliMJr55R7M3"
      },
      "source": [
        "def get_random_patch( img, patchWidth=psz ):\n",
        "    mystd = 0\n",
        "    while mystd == 0:\n",
        "        inds = get_random_base_ind()\n",
        "        hinds = [None,None]\n",
        "        for k in range(len(inds)):\n",
        "            hinds[k] = inds[k] + patchWidth\n",
        "        myimg = ants.crop_indices( img, inds, hinds )\n",
        "        mystd = myimg.std()\n",
        "    return myimg\n",
        "\n",
        "def get_random_patch_pair( img, img2, patchWidth=psz ):\n",
        "    mystd = 0\n",
        "    while mystd == 0:\n",
        "        inds = get_random_base_ind()\n",
        "        hinds = [None,None]\n",
        "        for k in range(len(inds)):\n",
        "            hinds[k] = inds[k] + patchWidth\n",
        "        myimg = ants.crop_indices( img, inds, hinds )\n",
        "        myimg2 = ants.crop_indices( img2, inds, hinds )\n",
        "        mystd = myimg.std()\n",
        "    return myimg, myimg2\n"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHFdGDENR7M3"
      },
      "source": [
        "set up vgg features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XVDGWvJR7M3"
      },
      "source": [
        "myvgg = VGG19(include_top=False, weights='imagenet',\n",
        "  input_shape=(psz,psz,3), pooling=None, classes=1000)\n",
        "# perceptual features - one can explore different layers and features\n",
        "# these layers - or combinations of these - are commonly used in the literature\n",
        "# as feature spaces for loss functions.  weighting terms relative to MSE are\n",
        "# also given in several papers which can help guide parameter setting.\n",
        "# **VGG54**\n",
        "myfeatmodel54 = tf.keras.Model( inputs=myvgg.inputs, outputs=myvgg.layers[20].output )\n",
        "# **VGG22**\n",
        "myfeatmodel22 = tf.keras.Model( inputs=myvgg.inputs, outputs=myvgg.layers[5].output )"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pvAoh7QR7M3"
      },
      "source": [
        "**loss term**<br>\n",
        "set up custom loss function with msq and vgg22 features - i have set the<br>\n",
        "parameters here manually to defaults that produced interesting results.<br>\n",
        "not making a claim that these are better or worse than other parameter sets.<br>\n",
        "VGG22 is shallow and fast to compute.<br>\n",
        "the loss function is a sum over:<br>\n",
        "1. mean squared intensity difference<br>\n",
        "2. VGG feature norms<br>\n",
        "3. an experimental neural QC-metric<br>\n",
        "4. an experimental neural QC-metric<br>\n",
        "5. the total variation loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uqb-my3R7M4"
      },
      "source": [
        "def my_loss_22(y_true, y_pred,\n",
        "  msqwt = tf.constant( 0.5 ),\n",
        "  qcWeight = tf.constant([50.0,5.0]),\n",
        "  fw=tf.constant(0.02),\n",
        "  tvwt = tf.constant( 1.0e-4 ) ):\n",
        "    squared_difference = tf.square(y_true - y_pred)\n",
        "    myax = [1,2,3]\n",
        "    msqTerm = tf.reduce_mean(squared_difference, axis=myax)\n",
        "    temp1 = myfeatmodel22(y_true)\n",
        "    temp2 = myfeatmodel22(y_pred)\n",
        "    vggsquared_difference = tf.square(temp1-temp2)\n",
        "    vggTerm = tf.reduce_mean(vggsquared_difference, axis=myax)\n",
        "    # an additional two-term loss based on NIMA\n",
        "#    qcTerm = tf.reduce_mean( tf.square( qcmodel( y_pred/127.5 ) - qcmodel( y_true/127.5 ) ), axis=[1]  )\n",
        "#    qcTerm = qcTerm[0] * qcWeight[0] + qcTerm[1] * qcWeight[1]\n",
        "    tvTerm = tf.reduce_mean( tf.image.total_variation( y_pred ) ) * tvwt\n",
        "#    return ( msqTerm * msqwt + vggTerm * fw + qcTerm + tvTerm )\n",
        "    return ( msqTerm * msqwt + vggTerm * fw + tvTerm )"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sk9I-9cER7M4"
      },
      "source": [
        "not used here - VGG54 is costlier b/c it's fairly deep in the VGG19 network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wy1c4pKaR7M4"
      },
      "source": [
        "def my_loss_54(y_true, y_pred):\n",
        "    squared_difference = tf.square(y_true - y_pred)\n",
        "    myax = [1,2,3]\n",
        "    msqTerm = tf.reduce_mean(squared_difference, axis=myax)\n",
        "    temp1 = myfeatmodel54(y_true)\n",
        "    temp2 = myfeatmodel54(y_pred)\n",
        "    vggsquared_difference = tf.square(temp1-temp2)\n",
        "    vggTerm = tf.reduce_mean(vggsquared_difference, axis=myax)\n",
        "    return ( msqTerm + vggTerm * featureWeight )"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNaMfEPwR7M4"
      },
      "source": [
        "**model instantiation**: these are close to defaults for the 2x network.<br>\n",
        "empirical evidence suggests that making covolutions and strides evenly<br>\n",
        "divisible by each other reduces artifacts.  2*3=6."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBYuxthgR7M4"
      },
      "source": [
        "mdl = dbpn( (None,None,3),\n",
        "  number_of_outputs=3,\n",
        "  number_of_base_filters=64,\n",
        "  number_of_feature_filters=256,\n",
        "  number_of_back_projection_stages=nbp,\n",
        "  convolution_kernel_size=(6, 6),\n",
        "  strides=(1, 1),\n",
        "  last_convolution=(3, 3), number_of_loss_functions=1, interpolation='nearest')"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGRW-v1CR7M5"
      },
      "source": [
        "collect all the images you have locally"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRNeVwHtR7M5",
        "outputId": "eace69af-2e95-44fd-8786-98302aedc805"
      },
      "source": [
        "print(\"assemble images\", flush=True )\n",
        "imgfns = glob.glob( \"/content/drive/MyDrive/xray_images/*png\")\n",
        "random.shuffle(imgfns)\n",
        "# 90\\% training data\n",
        "n = round( len( imgfns ) * 0.7 )\n",
        "imgfnsTrain = imgfns[0:n]      # just start small\n",
        "imgfnsTest = imgfns[(n+1):len(imgfns)]    # just a few test for now\n",
        "# get a reference image from the sample - we assume all are the same size\n",
        "# here which is true in this case.  small changes would be needed for\n",
        "# generalization.\n",
        "img = ants.image_read( imgfnsTrain[0] )\n",
        "print( imgfns )"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assemble images\n",
            "['/content/drive/MyDrive/xray_images/00006585_008.png', '/content/drive/MyDrive/xray_images/00006585_010.png', '/content/drive/MyDrive/xray_images/00006585_013.png', '/content/drive/MyDrive/xray_images/00006585_017.png', '/content/drive/MyDrive/xray_images/00006585_009.png', '/content/drive/MyDrive/xray_images/00006585_014.png', '/content/drive/MyDrive/xray_images/00006585_011.png', '/content/drive/MyDrive/xray_images/00006585_007.png', '/content/drive/MyDrive/xray_images/00006585_012.png', '/content/drive/MyDrive/xray_images/00006585_015.png', '/content/drive/MyDrive/xray_images/00006586_000.png', '/content/drive/MyDrive/xray_images/00006585_016.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = ants.image_read( imgfnsTrain[0] )\n",
        "img2 = ants.image_read( imgfnsTrain[1] )\n",
        "patch1, patch2 = get_random_patch_pair( img, img2 )\n",
        "ants.plot(patch1)\n",
        "ants.plot(patch2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "bWl05nhzxBwy",
        "outputId": "e622c6a9-51b0-408e-b1c6-d2f22f8ff7e4"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZFMyEaDR7M5"
      },
      "source": [
        "get pre-trained network weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24OTQndOR7M5",
        "outputId": "c958b8b4-010f-4007-becf-c21d5782c5a8"
      },
      "source": [
        "ofn='/content/drive/MyDrive/dbpnn-nbp5-ctmod4-patchscaleTrue-vggfeat22_p3eq.h5'\n",
        "print( os.path.isfile(ofn) )\n",
        "print( ofn )\n",
        "if os.path.isfile(ofn):\n",
        "    print( \"load \" + ofn )\n",
        "    mdl = tf.keras.models.load_model( ofn, compile=False )"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "/content/drive/MyDrive/dbpnn-nbp5-ctmod4-patchscaleTrue-vggfeat22_p3eq.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2mzvCQXR7M5"
      },
      "source": [
        "this is the experimental QC network - you may not have this in which case<br>\n",
        "you would comment this code out and in the loss function as well - results<br>\n",
        "will remain fairly similar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gF-2HMsQR7M6"
      },
      "source": [
        "qcmodelfn = \"resnet_koniq10k_QC_ThreeChan_MS_HR_patch_GlobalScaleMAE512x512.h5\"<br>\n",
        "qcmodel = tf.keras.models.load_model( qcmodelfn, compile=False )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GduGq-OPR7M6"
      },
      "source": [
        "set an optimizer - just standard Adam - may be sensitive to learning_rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21_MeKdxR7M6"
      },
      "source": [
        "ct = 0\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=1e-4)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJO2vl4dR7M6"
      },
      "source": [
        "model compilation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9UwV5PYR7M6"
      },
      "source": [
        "if do22:\n",
        "    mdl.compile(optimizer=opt, loss=my_loss_22)\n",
        "else:\n",
        "    mdl.compile(optimizer=opt, loss=my_loss_54)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcQrR3MnR7M6"
      },
      "source": [
        "resampling - use a custom antspynet layer for this (also in antsrnet)<br>\n",
        "key here is that these networks dont need to know the input spatial<br>\n",
        "dimensions in order to work effectively.  this is also a very tricky<br>\n",
        "part of TF: the coordinate system for resampling is different than, for<br>\n",
        "example, ITK.  not sure this is well-documented but it means that mixing<br>\n",
        "resampling done by TF and by ITK will not provide the same results and this<br>\n",
        "will impact training, inference, evaluation, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_khuK66rR7M6"
      },
      "source": [
        "myinput = tf.keras.layers.Input( [None,None,3] )\n",
        "mytarget = tf.keras.layers.Input( [None,None,3] )\n",
        "output = antspynet.ResampleTensorToTargetTensorLayer2D('linear')([myinput, mytarget])\n",
        "rmodel = tf.keras.Model(inputs=[myinput, mytarget], outputs=output)\n",
        "outputnn = antspynet.ResampleTensorToTargetTensorLayer2D('nearest_neighbor')([myinput, mytarget])\n",
        "rmodelnn = tf.keras.Model(inputs=[myinput, mytarget], outputs=outputnn)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmIBn7TCR7M7"
      },
      "source": [
        "build some test data - high res, low res and bilinear"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCNQ2k3-R7M7"
      },
      "source": [
        "if do_test:\n",
        "    mybs = 2 # FIXME may want to increase this for real training runs\n",
        "    patchesOrigTe = np.zeros(shape=(mybs,psz,psz,3))\n",
        "    patchesResamTe = np.zeros(shape=(mybs,psz,psz,3))\n",
        "    for myb in range(mybs):\n",
        "      imgfn = random.sample( imgfnsTest, 1 )[0]\n",
        "      img = ants.image_read( imgfn )\n",
        "      img = img - img.min()\n",
        "      img = img / img.max() * offsetIntensity*2.0 - offsetIntensity # for VGG\n",
        "      if img.components > 1:\n",
        "        img = ants.split_channels(img)[0]\n",
        "      rRotGenerator = ants.contrib.RandomRotate2D( ( 0, 50 ), reference=img )\n",
        "      tx0 = rRotGenerator.transform()\n",
        "      tx0inv = ants.invert_ants_transform(tx0)\n",
        "      rimg = tx0.apply_to_image( img )\n",
        "      rimg = tx0inv.apply_to_image( rimg )\n",
        "      img, rimg = get_random_patch_pair( img, rimg )\n",
        "      if patch_scale:\n",
        "        img = img - img.min()\n",
        "        rimg = rimg - rimg.min()\n",
        "      if img.max() > 0 and rimg.max() > 0 :\n",
        "        img = img / img.max() * offsetIntensity*2.0 - offsetIntensity # for VGG\n",
        "        rimg = rimg / rimg.max() * offsetIntensity*2.0 - offsetIntensity # for VGG\n",
        "      for k in range(3):\n",
        "        patchesOrigTe[myb,:,:,k] = img.numpy()\n",
        "        patchesResamTe[myb,:,:,k] = rimg.numpy()\n",
        "      patchesOrigTeTf = tf.cast( patchesOrigTe, \"float32\")\n",
        "      patchesResamTeTf = tf.cast( patchesResamTe, \"float32\")\n"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20spBnVvR7M7"
      },
      "source": [
        "**data generation**<br>\n",
        "recent versions of tensorflow/keras allow data generators to be passed<br>\n",
        "directly to the fit function.  underneath, this does a fairly efficient split<br>\n",
        "between GPU and CPU usage and data transfer.  EG probably knows more about this.<br>\n",
        "this generator randomly chooses between linear and nearest neighbor downsampling.<br>\n",
        "the *patch_scale* option can also be seen here which impacts how the network<br>\n",
        "sees/learns from image intensity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixgJKw7KR7M7"
      },
      "source": [
        "def my_generator( mybs , ntimesbatch = 16 ):\n",
        "    while True:\n",
        "        for myn in range(ntimesbatch):\n",
        "            patchesOrig = np.zeros(shape=(mybs,psz,psz,3))\n",
        "            patchesResam = np.zeros(shape=(mybs,psz,psz,3))\n",
        "            for myb in range(mybs):\n",
        "                imgfn = random.sample( imgfnsTrain, 1 )[0]\n",
        "                img = ants.image_read( imgfn )\n",
        "                img = img - img.min()\n",
        "                img = img / img.max() * offsetIntensity*2.0 - offsetIntensity # for VGG\n",
        "                if img.components > 1:\n",
        "                    img = ants.split_channels(img)[0]\n",
        "                rRotGenerator = ants.contrib.RandomRotate2D( ( 0, 50 ), reference=img )\n",
        "                tx0 = rRotGenerator.transform()\n",
        "                tx0inv = ants.invert_ants_transform(tx0)\n",
        "                rimg = tx0.apply_to_image( img )\n",
        "                rimg = tx0inv.apply_to_image( rimg )\n",
        "                img, rimg = get_random_patch_pair( img, rimg )\n",
        "                if patch_scale:\n",
        "                    img = img - img.min()\n",
        "                    rimg = rimg - rimg.min()\n",
        "                    if img.max() > 0 and rimg.max() > 0 :\n",
        "                        img = img / img.max() * offsetIntensity*2.0 - offsetIntensity # for VGG\n",
        "                        rimg = rimg / rimg.max() * offsetIntensity*2.0 - offsetIntensity # for VGG\n",
        "                for k in range(3):\n",
        "                    patchesOrig[myb,:,:,k] = img.numpy()\n",
        "                    patchesResam[myb,:,:,k] = rimg.numpy()\n",
        "            patchesOrig = tf.cast( patchesOrig, \"float32\")\n",
        "            patchesResam = tf.cast( patchesResam, \"float32\")\n",
        "            yield (patchesResam, patchesOrig)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "psz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lY840Nnou3Fs",
        "outputId": "53180e88-1e3a-47a9-f07e-a6861223db04"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJMW_sZNR7M7"
      },
      "source": [
        "instanstiate the generator function with a given sub-batch and total batch size<br>\n",
        "i dont entirely understand how this works (it's farily new) but it seems to<br>\n",
        "spit off sub-batches of the given size until it's exhausted the total number<br>\n",
        "of batches which would then count as an epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-osdoubmR7M7"
      },
      "source": [
        "mydatgen = my_generator( 32, 256 ) # FIXME for a real training run\n",
        "# mydatgen = my_generator( 4, 16 ) # FIXME for testing"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rvj1t-EtR7M7"
      },
      "source": [
        "to test the generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBMTdYxVR7M8"
      },
      "source": [
        "testit = next( mydatgen )"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gu06i3qsR7M8"
      },
      "source": [
        "set up some parameters for tracking performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wd2xCzc0R7M8"
      },
      "source": [
        "bestValLoss=1e12\n",
        "bestSSIM=0.0\n",
        "bestQC0 = -1000\n",
        "bestQC1 = -1000"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsYabjXWR7M8"
      },
      "source": [
        "we are going to run this for some indeterminate amount of time ie 5000 epochs<br>\n",
        "looks like i am doing some exponential smoothing here which is why the<br>\n",
        "variable wtsLast is stored.  i am not sure if workers > 1 would be effective."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nd8CHZqPR7M8"
      },
      "source": [
        "**training:** just call fit with the data generator<br>\n",
        "**evaluation:** after an epoch, run the model on the test data with some auxiliary metrics<br>\n",
        "**checkpoints:** use a greedy approach saving only the best performing network"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ETXfV9pt0Dm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exr1TmTFR7M8",
        "outputId": "93ecf044-605a-45f3-8063-efcc911110f7"
      },
      "source": [
        "print( \"begin training\", flush=True  )\n",
        "# mdl(patchesResamTeTf ).shape\n"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "begin training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmRi3VROR7M9",
        "outputId": "e8121dc8-23d7-4ae6-8aec-279766a5030a"
      },
      "source": [
        "for myrs in range( 1000 ):\n",
        "    wtsLast = mdl.get_weights()\n",
        "    tracker = mdl.fit( mydatgen,  epochs=1, steps_per_epoch=1, verbose=0,\n",
        "        validation_data=(patchesResamTeTf,patchesOrigTeTf),\n",
        "        workers = 1, use_multiprocessing=False )\n",
        "    print( \"ntrain: \" + str(myrs) + \" loss \" + str( tracker.history['loss'][0] ) + ' val-loss ' + str(tracker.history['val_loss'][0]), flush=True  )\n",
        "    wtsNext = mdl.get_weights()\n",
        "    # for ww in range( len( wtsNext ) ):\n",
        "    #    wtsNext[ww] = wtsNext[ww] * 0.01 + wtsLast[ww] * 0.99\n",
        "    mdl.set_weights( wtsNext )\n",
        "    pp = mdl.predict( patchesResamTeTf, batch_size = 1 )\n",
        "    myssimSR = tf.image.psnr( pp + offsetIntensity, patchesOrigTeTf+offsetIntensity, max_val=255 )\n",
        "    myssimSR = tf.reduce_mean( myssimSR ).numpy()\n",
        "    myssimBI = tf.image.psnr( patchesResamTeTf + offsetIntensity, patchesOrigTeTf+offsetIntensity, max_val=255 )\n",
        "    myssimBI = tf.reduce_mean( myssimBI ).numpy()\n",
        "    print( \"Patch PSNR: \" + str( myssimBI ) + \" SR: \" + str( myssimSR ), flush=True  )\n",
        "    if ( tracker.history['val_loss'][0] < bestValLoss ):\n",
        "        print(\"MyIT \" + str( myrs ) + \" IS BEST!!\", flush=True )\n",
        "        bestValLoss = tracker.history['val_loss'][0]\n",
        "        tf.keras.models.save_model( mdl, ofn )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ntrain: 0 loss 2471.62109375 val-loss 2942.08056640625\n",
            "Patch PSNR: 28.970352 SR: 13.702091\n",
            "MyIT 0 IS BEST!!\n",
            "ntrain: 1 loss 2098.347412109375 val-loss 2810.173828125\n",
            "Patch PSNR: 28.970352 SR: 13.904293\n",
            "MyIT 1 IS BEST!!\n",
            "ntrain: 2 loss 1475.8941650390625 val-loss 2676.33447265625\n",
            "Patch PSNR: 28.970352 SR: 14.1006775\n",
            "MyIT 2 IS BEST!!\n",
            "ntrain: 3 loss 1524.4217529296875 val-loss 2549.46142578125\n",
            "Patch PSNR: 28.970352 SR: 14.258609\n",
            "MyIT 3 IS BEST!!\n",
            "ntrain: 4 loss 1837.15234375 val-loss 2365.08203125\n",
            "Patch PSNR: 28.970352 SR: 14.658805\n",
            "MyIT 4 IS BEST!!\n",
            "ntrain: 5 loss 1962.6300048828125 val-loss 2113.72509765625\n",
            "Patch PSNR: 28.970352 SR: 15.409637\n",
            "MyIT 5 IS BEST!!\n",
            "ntrain: 6 loss 1497.314697265625 val-loss 1908.445556640625\n",
            "Patch PSNR: 28.970352 SR: 16.138485\n",
            "MyIT 6 IS BEST!!\n",
            "ntrain: 7 loss 1407.44189453125 val-loss 1750.473876953125\n",
            "Patch PSNR: 28.970352 SR: 16.760485\n",
            "MyIT 7 IS BEST!!\n",
            "ntrain: 8 loss 1142.44384765625 val-loss 1567.122314453125\n",
            "Patch PSNR: 28.970352 SR: 17.690472\n",
            "MyIT 8 IS BEST!!\n",
            "ntrain: 9 loss 994.0213623046875 val-loss 1490.61669921875\n",
            "Patch PSNR: 28.970352 SR: 18.226814\n",
            "MyIT 9 IS BEST!!\n",
            "ntrain: 10 loss 1590.8953857421875 val-loss 1372.1212158203125\n",
            "Patch PSNR: 28.970352 SR: 18.642399\n",
            "MyIT 10 IS BEST!!\n",
            "ntrain: 11 loss 1415.408447265625 val-loss 1363.911865234375\n",
            "Patch PSNR: 28.970352 SR: 18.460232\n",
            "MyIT 11 IS BEST!!\n",
            "ntrain: 12 loss 865.631103515625 val-loss 1387.064453125\n",
            "Patch PSNR: 28.970352 SR: 18.262365\n",
            "ntrain: 13 loss 1672.873779296875 val-loss 1393.6630859375\n",
            "Patch PSNR: 28.970352 SR: 18.147423\n",
            "ntrain: 14 loss 1849.705078125 val-loss 1386.7791748046875\n",
            "Patch PSNR: 28.970352 SR: 18.14391\n",
            "ntrain: 15 loss 1442.90576171875 val-loss 1397.422119140625\n",
            "Patch PSNR: 28.970352 SR: 18.038689\n",
            "ntrain: 16 loss 1101.9466552734375 val-loss 1401.98291015625\n",
            "Patch PSNR: 28.970352 SR: 17.971737\n",
            "ntrain: 17 loss 1803.781494140625 val-loss 1393.505615234375\n",
            "Patch PSNR: 28.970352 SR: 17.933617\n",
            "ntrain: 18 loss 1313.967041015625 val-loss 1407.505126953125\n",
            "Patch PSNR: 28.970352 SR: 17.822872\n",
            "ntrain: 19 loss 1145.4407958984375 val-loss 1425.4808349609375\n",
            "Patch PSNR: 28.970352 SR: 17.719471\n",
            "ntrain: 20 loss 1202.87939453125 val-loss 1424.90771484375\n",
            "Patch PSNR: 28.970352 SR: 17.706326\n",
            "ntrain: 21 loss 1360.83056640625 val-loss 1400.668701171875\n",
            "Patch PSNR: 28.970352 SR: 17.801796\n",
            "ntrain: 22 loss 1138.6845703125 val-loss 1353.46875\n",
            "Patch PSNR: 28.970352 SR: 18.01918\n",
            "MyIT 22 IS BEST!!\n",
            "ntrain: 23 loss 1107.642578125 val-loss 1290.355224609375\n",
            "Patch PSNR: 28.970352 SR: 18.36074\n",
            "MyIT 23 IS BEST!!\n",
            "ntrain: 24 loss 1225.8914794921875 val-loss 1215.28271484375\n",
            "Patch PSNR: 28.970352 SR: 18.857954\n",
            "MyIT 24 IS BEST!!\n",
            "ntrain: 25 loss 1079.9788818359375 val-loss 1139.513427734375\n",
            "Patch PSNR: 28.970352 SR: 19.598839\n",
            "MyIT 25 IS BEST!!\n",
            "ntrain: 26 loss 745.01953125 val-loss 1140.24462890625\n",
            "Patch PSNR: 28.970352 SR: 19.876225\n",
            "ntrain: 27 loss 866.3883056640625 val-loss 1247.090576171875\n",
            "Patch PSNR: 28.970352 SR: 19.153976\n",
            "ntrain: 28 loss 1506.0849609375 val-loss 1174.2666015625\n",
            "Patch PSNR: 28.970352 SR: 19.578825\n",
            "ntrain: 29 loss 848.213623046875 val-loss 1099.8023681640625\n",
            "Patch PSNR: 28.970352 SR: 19.927078\n",
            "MyIT 29 IS BEST!!\n",
            "ntrain: 30 loss 693.0943603515625 val-loss 1088.084716796875\n",
            "Patch PSNR: 28.970352 SR: 19.749876\n",
            "MyIT 30 IS BEST!!\n",
            "ntrain: 31 loss 788.625 val-loss 1094.1925048828125\n",
            "Patch PSNR: 28.970352 SR: 19.537022\n",
            "ntrain: 32 loss 1041.841796875 val-loss 1105.6710205078125\n",
            "Patch PSNR: 28.970352 SR: 19.34349\n",
            "ntrain: 33 loss 889.3433837890625 val-loss 1099.5751953125\n",
            "Patch PSNR: 28.970352 SR: 19.357025\n",
            "ntrain: 34 loss 1614.6182861328125 val-loss 1071.1815185546875\n",
            "Patch PSNR: 28.970352 SR: 19.60912\n",
            "MyIT 34 IS BEST!!\n",
            "ntrain: 35 loss 1361.929931640625 val-loss 1048.693359375\n",
            "Patch PSNR: 28.970352 SR: 19.846203\n",
            "MyIT 35 IS BEST!!\n",
            "ntrain: 36 loss 1274.662353515625 val-loss 1051.4993896484375\n",
            "Patch PSNR: 28.970352 SR: 19.861519\n",
            "ntrain: 37 loss 849.2110595703125 val-loss 1079.552734375\n",
            "Patch PSNR: 28.970352 SR: 19.62167\n",
            "ntrain: 38 loss 916.33544921875 val-loss 1093.0078125\n",
            "Patch PSNR: 28.970352 SR: 19.471277\n",
            "ntrain: 39 loss 904.9537963867188 val-loss 1063.3369140625\n",
            "Patch PSNR: 28.970352 SR: 19.668592\n",
            "ntrain: 40 loss 1209.3782958984375 val-loss 1012.4512939453125\n",
            "Patch PSNR: 28.970352 SR: 20.057182\n",
            "MyIT 40 IS BEST!!\n",
            "ntrain: 41 loss 1113.91552734375 val-loss 984.621337890625\n",
            "Patch PSNR: 28.970352 SR: 20.229996\n",
            "MyIT 41 IS BEST!!\n",
            "ntrain: 42 loss 884.2701416015625 val-loss 983.1688232421875\n",
            "Patch PSNR: 28.970352 SR: 20.063828\n",
            "MyIT 42 IS BEST!!\n",
            "ntrain: 43 loss 568.7257690429688 val-loss 981.9907836914062\n",
            "Patch PSNR: 28.970352 SR: 19.962915\n",
            "MyIT 43 IS BEST!!\n",
            "ntrain: 44 loss 575.266845703125 val-loss 962.44091796875\n",
            "Patch PSNR: 28.970352 SR: 20.11967\n",
            "MyIT 44 IS BEST!!\n",
            "ntrain: 45 loss 969.167724609375 val-loss 929.0631103515625\n",
            "Patch PSNR: 28.970352 SR: 20.622429\n",
            "MyIT 45 IS BEST!!\n",
            "ntrain: 46 loss 1045.490478515625 val-loss 926.8717041015625\n",
            "Patch PSNR: 28.970352 SR: 20.729073\n",
            "MyIT 46 IS BEST!!\n",
            "ntrain: 47 loss 609.7774658203125 val-loss 915.9420166015625\n",
            "Patch PSNR: 28.970352 SR: 20.910582\n",
            "MyIT 47 IS BEST!!\n",
            "ntrain: 48 loss 806.9181518554688 val-loss 893.5696411132812\n",
            "Patch PSNR: 28.970352 SR: 21.088655\n",
            "MyIT 48 IS BEST!!\n",
            "ntrain: 49 loss 999.901123046875 val-loss 872.514404296875\n",
            "Patch PSNR: 28.970352 SR: 21.216618\n",
            "MyIT 49 IS BEST!!\n",
            "ntrain: 50 loss 554.1378173828125 val-loss 869.1470947265625\n",
            "Patch PSNR: 28.970352 SR: 21.173647\n",
            "MyIT 50 IS BEST!!\n",
            "ntrain: 51 loss 1087.1552734375 val-loss 879.34814453125\n",
            "Patch PSNR: 28.970352 SR: 20.91917\n",
            "ntrain: 52 loss 485.5371398925781 val-loss 887.661865234375\n",
            "Patch PSNR: 28.970352 SR: 20.727356\n",
            "ntrain: 53 loss 918.4070434570312 val-loss 881.68359375\n",
            "Patch PSNR: 28.970352 SR: 20.666992\n",
            "ntrain: 54 loss 808.61572265625 val-loss 864.861083984375\n",
            "Patch PSNR: 28.970352 SR: 20.717365\n",
            "MyIT 54 IS BEST!!\n",
            "ntrain: 55 loss 1265.93310546875 val-loss 879.459228515625\n",
            "Patch PSNR: 28.970352 SR: 20.390234\n",
            "ntrain: 56 loss 1129.166015625 val-loss 922.5682983398438\n",
            "Patch PSNR: 28.970352 SR: 19.888548\n",
            "ntrain: 57 loss 642.7321166992188 val-loss 938.6400756835938\n",
            "Patch PSNR: 28.970352 SR: 19.698719\n",
            "ntrain: 58 loss 1639.245361328125 val-loss 909.73681640625\n",
            "Patch PSNR: 28.970352 SR: 19.93863\n",
            "ntrain: 59 loss 863.9171752929688 val-loss 892.4686279296875\n",
            "Patch PSNR: 28.970352 SR: 20.079653\n",
            "ntrain: 60 loss 1789.08984375 val-loss 861.5363159179688\n",
            "Patch PSNR: 28.970352 SR: 20.367607\n",
            "MyIT 60 IS BEST!!\n",
            "ntrain: 61 loss 566.0243530273438 val-loss 814.609619140625\n",
            "Patch PSNR: 28.970352 SR: 20.884356\n",
            "MyIT 61 IS BEST!!\n",
            "ntrain: 62 loss 774.6279296875 val-loss 785.15771484375\n",
            "Patch PSNR: 28.970352 SR: 21.233736\n",
            "MyIT 62 IS BEST!!\n",
            "ntrain: 63 loss 550.3214721679688 val-loss 770.1273193359375\n",
            "Patch PSNR: 28.970352 SR: 21.497526\n",
            "MyIT 63 IS BEST!!\n",
            "ntrain: 64 loss 855.1381225585938 val-loss 769.4005126953125\n",
            "Patch PSNR: 28.970352 SR: 21.603542\n",
            "MyIT 64 IS BEST!!\n",
            "ntrain: 65 loss 660.8739624023438 val-loss 761.764404296875\n",
            "Patch PSNR: 28.970352 SR: 21.806515\n",
            "MyIT 65 IS BEST!!\n",
            "ntrain: 66 loss 1139.7862548828125 val-loss 742.2462158203125\n",
            "Patch PSNR: 28.970352 SR: 21.927135\n",
            "MyIT 66 IS BEST!!\n",
            "ntrain: 67 loss 844.4136962890625 val-loss 791.81298828125\n",
            "Patch PSNR: 28.970352 SR: 20.898975\n",
            "ntrain: 68 loss 1008.01513671875 val-loss 831.0264892578125\n",
            "Patch PSNR: 28.970352 SR: 20.30798\n",
            "ntrain: 69 loss 428.44256591796875 val-loss 836.17724609375\n",
            "Patch PSNR: 28.970352 SR: 20.210247\n",
            "ntrain: 70 loss 597.00390625 val-loss 822.3543090820312\n",
            "Patch PSNR: 28.970352 SR: 20.339893\n",
            "ntrain: 71 loss 767.8716430664062 val-loss 802.183349609375\n",
            "Patch PSNR: 28.970352 SR: 20.558458\n",
            "ntrain: 72 loss 668.7631225585938 val-loss 764.3765258789062\n",
            "Patch PSNR: 28.970352 SR: 21.025684\n",
            "ntrain: 73 loss 411.8353271484375 val-loss 722.796630859375\n",
            "Patch PSNR: 28.970352 SR: 21.687748\n",
            "MyIT 73 IS BEST!!\n",
            "ntrain: 74 loss 501.3179931640625 val-loss 704.3865966796875\n",
            "Patch PSNR: 28.970352 SR: 22.123875\n",
            "MyIT 74 IS BEST!!\n",
            "ntrain: 75 loss 651.1253662109375 val-loss 714.8978881835938\n",
            "Patch PSNR: 28.970352 SR: 22.01258\n",
            "ntrain: 76 loss 630.4927978515625 val-loss 708.5095825195312\n",
            "Patch PSNR: 28.970352 SR: 22.185532\n",
            "ntrain: 77 loss 404.6567077636719 val-loss 704.2264404296875\n",
            "Patch PSNR: 28.970352 SR: 22.403845\n",
            "MyIT 77 IS BEST!!\n",
            "ntrain: 78 loss 802.3013916015625 val-loss 688.0020751953125\n",
            "Patch PSNR: 28.970352 SR: 22.64402\n",
            "MyIT 78 IS BEST!!\n",
            "ntrain: 79 loss 288.60113525390625 val-loss 689.9448852539062\n",
            "Patch PSNR: 28.970352 SR: 22.389341\n",
            "ntrain: 80 loss 734.154052734375 val-loss 686.248779296875\n",
            "Patch PSNR: 28.970352 SR: 22.103256\n",
            "MyIT 80 IS BEST!!\n",
            "ntrain: 81 loss 616.8206787109375 val-loss 679.5737915039062\n",
            "Patch PSNR: 28.970352 SR: 21.96915\n",
            "MyIT 81 IS BEST!!\n",
            "ntrain: 82 loss 466.46038818359375 val-loss 671.2235107421875\n",
            "Patch PSNR: 28.970352 SR: 21.996788\n",
            "MyIT 82 IS BEST!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.image.psnr( pp + offsetIntensity, patchesOrigTeTf+offsetIntensity, 255)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTnilZaG3Rum",
        "outputId": "79962135-41d3-4d9b-d97e-37cd0431c6b9"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([11.155731, 15.619099], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEBJUsFhR7M9"
      },
      "source": [
        "**helper examples**<br>\n",
        "below, full image inference code - just an example of one way to apply the learned model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xd0j4qLmR7M9"
      },
      "source": [
        "imgfnt = random.sample( imgfnsTest, 1 )[0]\n",
        "imgt = ants.image_read( imgfnt )\n",
        "if imgt.components > 1:\n",
        "    imgt = ants.split_channels(imgt)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aR6S5_XbR7M9"
      },
      "source": [
        "outdim = (512,512)\n",
        "imgl = ants.resample_image( imgt, outdim, use_voxels=True, interp_type=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4F8-Zr5R7M-"
      },
      "source": [
        "imglm = ants.merge_channels( [imgl,imgl,imgl])\n",
        "sro = antspynet.apply_super_resolution_model_to_image( imglm,\n",
        "  tf.keras.models.load_model( ofn, compile=False ) )\n",
        "srs = ants.split_channels( sro )\n",
        "sr = ( srs[0]+srs[1]+srs[2] ) * 1.0/3.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yvN423gR7M-"
      },
      "source": [
        "sro = ants.copy_image_info( imgt, sro )\n",
        "sr = ants.copy_image_info( imgt, sr )\n",
        "imgu = ants.resample_image( imgl, imgt.shape, use_voxels=True, interp_type=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeFpMx6oR7M-"
      },
      "source": [
        "some metrics on the output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bj78wMEJR7M_"
      },
      "source": [
        "gmsdSR = antspynet.gmsd(imgt,sr)\n",
        "gmsdBi = antspynet.gmsd(imgt,imgu)\n",
        "ssimSR = antspynet.ssim(imgt,sr)\n",
        "ssimBi = antspynet.ssim(imgt,imgu)\n",
        "psnrSR = antspynet.psnr(imgt,sr)\n",
        "psnrBi = antspynet.psnr(imgt,imgu)\n",
        "print(\"PSNR Test: \" + str( psnrBi ) + \" vs SR: \" + str( psnrSR ), flush=True  )\n",
        "print(\"GMSD Test: \" + str( gmsdBi ) + \" vs SR: \" + str( gmsdSR ), flush=True  )\n",
        "print(\"ssim Test: \" + str( ssimBi ) + \" vs SR: \" + str( ssimSR ), flush=True  )\n",
        "# ants.image_write( imgt, '/tmp/tempGTz.nii.gz' )\n",
        "# ants.image_write( sro, '/tmp/tempSRz.nii.gz' )\n",
        "# ants.image_write( imgu, '/tmp/tempUpz.nii.gz' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1U1XScQR7M_"
      },
      "source": [
        "look at loss weights - should parameterize to make sure consistent with loss.<br>\n",
        "this lets one take a look at intermediate results and manually adjust the<br>\n",
        "relative weights of each term."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4c92fhoR7M_"
      },
      "source": [
        "patchesPred = mdl( patchesLoTe )\n",
        "squared_difference = tf.square(patchesPred - patchesHiTe)\n",
        "msqTerm = tf.reduce_mean(squared_difference )\n",
        "vggTerm = tf.reduce_mean(tf.square(myfeatmodel22(patchesHiTe)-myfeatmodel22(patchesPred)))\n",
        "# qcTerm = tf.reduce_mean( tf.square( qcmodel( patchesPred/127.5 ) - qcmodel( patchesHiTe/127.5 ) ), axis=[0])\n",
        "tvTerm = tf.reduce_mean( tf.image.total_variation( patchesPred ) )\n",
        "print( msqTerm )\n",
        "print( vggTerm * 0.02 )\n",
        "# print( qcTerm * [50.0,0.5] )\n",
        "print( tvTerm * 1e-4 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6bmOh_XR7M_"
      },
      "source": [
        "simple plot example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuHiPEy3R7NA"
      },
      "source": [
        "wh=1 # 129\n",
        "comparisonimg = ants.from_numpy( np.concatenate(\n",
        " [ np.array(tf.squeeze(patchesUpTe[wh,:,:,1]).numpy()+ 127.5),\n",
        "   np.array(tf.squeeze(patchesPred[wh,:,:,1]).numpy() + 127.5),\n",
        "   np.array(tf.squeeze(patchesHiTe[wh,:,:,1]).numpy()+ 127.5) ], axis=0 ) )\n",
        "ants.plot( comparisonimg )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfql0HjQR7NA"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}